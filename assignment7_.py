# -*- coding: utf-8 -*-
"""Assignment7_10170832.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fkCxc5BUmlrJkchIB6EThvLHST-h-6yh
"""

# Commented out IPython magic to ensure Python compatibility.
#Load base packages 
import pandas as pd
import numpy as np 
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn import preprocessing
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.utils import to_categorical

#Load the dataset in with label mode = fine, and split the data into train and test data
(X_train,y_train), (X_test,y_test)= tf.keras.datasets.cifar100.load_data(
    label_mode='fine')


print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

#These are the subclass labels#, these will be used when attempting to predict model outputs.
classes= '''
beaver, dolphin, otter, seal, whale, aquarium fish, flatfish, ray, shark, trout, orchids, poppies, roses, sunflowers, tulips, bottles, bowls, cans, cups, plates, apples, mushrooms, oranges, pears, sweet peppers
, clock, computer keyboard, lamp, telephone, television, bed, chair, couch, table, wardrobe, bee, beetle, butterfly, caterpillar, cockroach, bear, leopard, lion, tiger, wolf, bridge, castle, house, road, skyscraper
, cloud, forest, mountain, plain, sea, camel, cattle, chimpanzee, elephant, kangaroo, fox, porcupine, possum, raccoon, skunk, crab, lobster, snail, spider, worm, baby, boy, girl, man, woman
, crocodile, dinosaur, lizard, snake, turtle, hamster, mouse, rabbit, shrew, squirrel, maple, oak, palm, pine, willow, bicycle, bus, motorcycle, pickup truck, train, lawn-mower, rocket, streetcar, tank, tractor
'''.split(" ")

#Reshape the variables to fit our data style. This will help us when trying to import it into the 
#CNN model
X_train = X_train.reshape(-1,32,32, 3)
X_test = X_test.reshape(-1,32,32, 3)
print(X_train.shape)
print(X_test.shape)
print(y_test.shape)
print(y_train.shape)

#Change pixel size from 0-1, and also make sure the datatype is float32
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train = X_train / 255
X_test = X_test / 255

'''
Now we will create our CNN model. Using trial and error we can add various layers and try different combonations of activation values. THis will help optimize the 
results of the model. First I created a base model, and then kept adding layers/changing variables to see what would work best. I have settled on the model below, using
the various layers and activation combinations. 
'''

model = Sequential()
model.add(Conv2D(64, (3,3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(.25))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(100, activation='softmax'))
  
model.summary()
model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])

''' Now we can fit our model on our test data and see how it does in terms of accuracy and loss'''
history = model.fit(X_train,y_train, epochs=20)
#
valLoss, accuracy = model.evaluate(X_test,  y_test)
print("value loss of final model: {}\nAccuracy of final model: {} ".format(valLoss, accuracy))

"""**PREDICTION**

To be able to predict values from the model I created a shape of 5 outputs, and made it into a sample. I then created a 'prediction' variable which will house all of our random predicted sampels.
"""

idx = np.random.randint(X_test.shape[0],size = 5)
sample = X_test[idx,:]
#

prediction = np.argmax(model.predict(sample),axis = 1)

"""Once this was created, I then created a for loop which would find our predictions within the class list as shown earlier and give them a title, this title would be what the model predicted for the image. """

fig,axes = plt.subplots(1,5, figsize = (20,10))
for i in range(5): 
  axes[i].imshow(sample[i])
  axes[i].set_title(f'{classes[prediction[i]]}')
plt.show()